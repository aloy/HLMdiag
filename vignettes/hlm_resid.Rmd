---
title: "HLMDiag Residual Diagnostics"
authors: "Jack Moran, Jaylin Lowe, Adam Loy"
date: "'Sys.Date()'"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{hlm_resid}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# HLMdiag: a diagnostic tool for hierarchical (multilevel) linear models

`HLMdiag` was created in order to provide a unified framework for analysts to diagnose hierarchical linear models (HLMs). While it is possible to extract most types of influence diagnostics and residuals from a given model, the process is often uses various functions across multiple packages, each of which has its own syntax and quirks. HLMdiag provides diagnostic tools targeting all aspects and levels of hierarchical linear models in a single package. In this update especially, `HLMdiag` has focused on usability in its functions. Drawing inspiration from the `augment` function in the `broom` package, the new functions `hlm_resid`, `hlm_influence`, and `hlm_augment` append diagnostic information to a model's data frame, allowing the analyst to easily work with and see how these results relate to the original variables.

This vignette introduces new functions concerning residual diagnostics in `HLMdiag`, specifically `hlm_resid`, `pull_resid`, and `hlm_augment`. The function `hlm_resid` is intended to replace `HLMresid` in functionality, and works more robustly with 3-level models as well as models fit with `nlme`. `hlm_resid` returns a tibble of the model frame, residuals and fitted values making it simple for an analyst to diagnose a model. 

For information about influence diagnostics like Cook's distance and leverage in HLMs, the reader should see the *influence vignette*. 

## hlm_resid function

The function `hlm_resid` takes a hierarchical linear model fit as a `lmerMod` or `lme` object and extracts residuals and predicted values from the model using both Least Squares (LS) and Empirical Bayes (EB) methods in estimating parameters. Whereas the old function, `HLMresid`, would return a vector with a single type of residual, `hlm_resid` appends specified residuals to the data frame of the model in the form of a tibble. The use of a tibble allows the analyst to easily plot residuals against explanatory variables and identify possible outliers or model deficiencies. The function draws heavy inspiration from the `augment` function of the `broom` package, however offers more options for the types of residuals that the analyst may want to use.

## Types of residuals in multilevel models

The presence of multiple sources of variability in hierarchical linear models results in numerous quantities defining residuals. All functions in `HLMdiag` follow the classification by *Hilden-Minton (1995)* and define three types of residuals:

1. level-1 (conditional) residuals
1. higher level (random effects) residuals
1. marginal (composite) residuals

The definitions of level-1 and higher level residuals lead to different residuals depending on how the fixed and random model coefficients are estimated. `hlm_resid` implements two estimation methods: Least Squares estimation and Empirical Bayes estimation. For a comprehensive discussion of these two methods and how they are implemented, we direct the reader to the release paper for `HLMdiag` in the *Journal of Statistical Softwrare*. 

LS and EB residuals each have their own advantages and disadvantages. Level-1 LS residuals are calculated by fitting separate linear models to each group and using LS to estimate the fixed and random effects. Because they rely only on the first level of hierarchy, they are unconfounded with higher level residuals and a useful first step in diagnosing a model; however, for small group sample sizes, LS residuals are unreliable. Level-1 EB residuals are defined as the conditional modes of the random effects given the data and the estimated parameter values, which are calculated with maximum likelihood. They are confounded with higher level residuals, but more robust with small sample sizes. For higher level residuals, coefficients can again be estimated using either LS or EB, but EB residuals are generally prefered due to small group level sample sizes. `hlm_resid` can return both LS and EB level-1 and higher level residuals as well as marginal residuals.

## Example Data

To illustrate the use of `hlm_resid`, we make use of data on exam scores of 4,059 students in 65 inner London schools. This data set is distributed as part of the R package `mlmRev` (*Bates, Maechler, and Bolker 2013b*), which makes well known multilevel modeling data sets available in R.
```{r}
data("Exam", package = "mlmRev")
head(Exam)
```

For each student, the data consist of their gender (`sex`) and two standardized exam scores—- an intake score on the London Reading Test (LRT) at age 11 (`standLRT`) and a score on the General Certificate of Secondary Education (GCSE) examination at age 16 (`normexam`). Additionally, the students’ LRT scores were used to segment students into three categories (bottom 25%, middle 50%, and top 25%) based on their verbal reasoning subscore (`vr`) and overall score (`intake)`. At the school level, the data contain the average intake score for the school (`schavg`) and type based on school gender (`schgend`, coded as mixed, boys, or girls).

## hlm_resid usage

`hlm_resid` takes 5 arguments:

* `object` - the model fit as a `lmerMod` or `lme` object.
* `level` - the level at which residuals should be extracted. The default is `level = 1`, which returns both EB and LS level-1  residuals as well as marginal residuals. Can also be set to a grouping level as defined in `names(object@flist)` in `lme4` or in `names(object$groups)` in `nlme`. When set to a grouping level, returns both EB and LS higher level residuals, otherwise known as the random effects for each group. 
* `standardize` - a logical indicating if the returned residuals should be standardized. The default is `standardize = FALSE`, returning raw residuals. When `standardize = TRUE`, residuals are standardized by the sigma components of the model object. For marginal residuals, standardized residuals are equivalent to the Cholesky residuals.
* `include.ls` - a logical indicating if LS residuals should be included in the tibble. The default is `include.ls = TRUE`. The LS method of estimating residuals is more computationally intensive than the EB method, and thus setting `include.ls = FALSE` decreases the runtime substantially on models with many observations.
* `data` - only necesarry if `na.action = na.exclude` for the model object. `data` should take the data set used to fit the model containing observations with NA values.

We illustrate usage for `hlm_resid` using the exam data introduced above and fitting an initial two-level HLM using a student’s standardized London Reading Test intake score (standLRT) to explain their GCSE exam score allowing for a random intercept for each school:
```{r}
fm1 <- lme4::lmer(normexam ~ standLRT + (1 | school), Exam, REML = FALSE)
fm1
```

### General usage

Here we will demonstrate how to extract all types of residuals from the model `fm1` before moving on to a more comprehensive analysis of the model. To extract level-1 raw residuals, we use the following call.
```{r, message = FALSE}
library(HLMdiag)
hlm_resid(fm1)
```

`hlm_resid` appends 6 columns to the model's data frame:

* `.resid`  the raw Empirical Bayes (EB) residuals for each observation
* `.fitted` the Empirical Bayes (EB) fitted values
* `.ls.resid`  the raw Least Squares (LS) residuals
* `.ls.fitted` the Least Squares fitted values
* `.mar.resid`  the raw marginal residuals
* `.mar.fitted` the marginal fitted values

Note that the columns containing the Empirical Bayes residuals are simply named `.resid` and `.fitted`. This is because both `lme4::resid()` and `nlme::resid()` use the EB method in estimating residuals, thus the analyst is likely more familiar with this type of residual.

### standardize and include.ls

We can alter the output of the level-1 residuals using the `standardize` and `include.ls` parameters introduced above. The following call returns standardized level-1 residuals, excluding the least squares residuals.
```{r}
hlm_resid(fm1, standardize = TRUE, include.ls = FALSE)
```

`hlm_resid` appends the EB and marginal residual columns to the model's data frame. The names of the columns containing residuals now have the prefix `.std` to reflect the fact that they are stanardized. Note that standardized marginal residuals are equivalent to the Cholesky residuals of a HLM and thus are named `.chol.mar.resid`.

### Higher-level residuals

To access higher level residuals, we can set the `level` parameter to a grouping level as defined in `names(object@flist)` in `lme4` or in `names(object$groups)` in `nlme`. To extract the school-level residuals, otherwise known as the random effects for school, we use the following call.
```{r}
names(fm1@flist)
hlm_resid(fm1, level = "school")
```

In the tibble returned by `hlm_resid`, each row now represents one of the groups specified by the `level` parameter. In this example, there were 65 schools from which data was collected, and the resulting tibble has 65 rows. If we had included school-level variables in the model, such as the average intake score for a school (`schavg`), those variables would also be included in the output. The final two columns contain the random effects for intercept at the school.

* `.ranef.intercept` the random effects for intercept, using Empirical Bayes estimation
* `.ls.intercept` the random effects for intercept, using Least Squares estimation

Had we included other random effect terms in the model, the EB and LS estimations of their random effects would also be included in the output. Again, the EB random effects are simply named `.ranef` because it is assumed that the analyst is most familiar with this type of random effect The parameters `standardize` and `include.ls` work the same way with higher-level residuals and with both `lmerMod` and `lme` objects. Setting `include.ls = FALSE` is often recommended with higher-level residuals, as calculating LS residuals is computationally intensive and the resulting residuals are often unreliable due to small group level sample sizes.

### na.action and data

The final parameter, `data`, is an argument that becomes required when `na.action = na.exclude` for the model object. To demonstrate this requirement, we create a duplicate data set of `Exam` with the standardized LRT scores set to `NA` for observations 1, 2, and 5.
```{r}
# make copy of Exam data set
Exam2 <- Exam              
# set standLRT to NA for 3 observations
Exam2[c(1,2,5),7] <- NA    
# refit model with na.exclude
fm1.NA <- lme4::lmer(normexam ~ standLRT + (1 | school), Exam2,  
               na.action = na.exclude, REML = FALSE)

```

In the first example, when we try to call `hlm_resid` on our model object, it throws an informative error asking for the data set used to fit the model. We provide this using the `data` parameter in the second example.
```{r, error = TRUE}
# incorrect:
hlm_resid(fm1.NA) 

# correct:
hlm_resid(fm1.NA, data = Exam2) 
```

### Three level models

In three level models, the function call to access the middle-level residuals changes depending on whether a model is a `lmerMod` or `lme` object. This is due to how `lme4` and `nlme` use different approaches in how they store their grouping levels. To demonstrate this, we use a classroom data set from the book, *Linear Mixed Models: A Practical Guide Using Statistical Software*. The data contains math testing scores from 1190 children in 312 different classroom within 107 unique schools. All classrooms are nested within schools, and all students are nested within a single classroom, thus it is an excellent example for a three level model.
```{r}
class <- read.csv("http://www-personal.umich.edu/~bwest/classroom.csv")
head(class)
```

The data set contains 12 columns; however, we are only interested in the response variable, `mathgain`, and the grouping variables`classid`, and `schoolid`. We fit the simple unconditional means model in both `lme4` and `nlme` below.
```{r}
fm2.lmer <- lme4::lmer(mathgain ~ 1 + (1|schoolid/classid), data = class)

fm2.lme <- nlme::lme(mathgain ~ 1, random = ~1|schoolid/classid, data = class)
```

For both models, classroom is nested within school. We can access the grouping levels for each model with the following:
```{r}
names(fm2.lmer@flist)
names(fm2.lme$groups)
```

To extract the classroom level random effects for `fm2.lmer`, fit with `lme4`, we set `level = "classid:schoolid"`. For the `fm2.lmer`, fit with `nlme`, we set `level = "classid"`.
```{r}
# lme4
hlm_resid(fm2.lmer, level = "classid:schoolid")

# nlme
hlm_resid(fm2.lme, level = "classid")
```

The order of `classid` and `schoolid` in the returned tibble is based on the convention for the package in which the model was fit. 

## Using hlm_resid in context

Now that we have shown how to extract all types of residuals for hierarchical models using `hlm_resid`, we illustrate how to use those residuals in context to evaluate a model. We will diagnose the earlier model, `fm1` fit on the `Exam` data set above. We use `hlm_resid` to extract the level-1 standardized residuals.
```{r}
resid1_fm1 <- hlm_resid(fm1, level = 1, standardize = TRUE)
resid1_fm1
```

Utilizing the tibble output of `hlm_resid`, we can easily plot the standardized LS residuals against explanatory variables such as the standardized LRT score or against the fitted values. We use the LS residuals at level-1 because they are unconfounded of higher level residuals.
```{r, message = FALSE, warning = FALSE}
library(ggplot2)
ggplot(data = resid1_fm1, aes(x = standLRT, y = .std.ls.resid)) + 
  geom_point() +
  geom_smooth(method = "loess") + 
  labs(y = "LS level-1 residuals", title = "LS residuals against standardized LRT score")

ggplot(data = resid1_fm1, aes(x = id, y = .std.ls.resid)) + 
  geom_point() +
  geom_smooth(method = "loess") + 
  labs(y = "LS level-1 residuals", title = "LS residuals against observation id")
```

The smoother shows that standardized LRT scores might not be linearly related to GCSE exam scores. Likelihood ratio tests (not shown) confirm that quadratic and cubic terms for `standLRT` contribute significantly in describing GCSE exam scores, so we incorporate these terms in the updated model, `fm1b`. We then reassess the level-1 LS residuals.
```{r, message = FALSE, warning = FALSE}
fm1b <- lme4::lmer(normexam ~ standLRT + I(standLRT^2) + I(standLRT^3) + (1 | school), 
             Exam, REML = FALSE)
resid1_fm1b <- hlm_resid(fm1b, level = 1, standardize = TRUE)

ggplot(data = resid1_fm1b, aes(x = standLRT, y = .std.ls.resid)) + 
  geom_point() +
  geom_smooth(method = "loess") + 
  labs(y = "LS level-1 residuals", title = "LS residuals against standardized LRT score")
```

The addition of the quadratic and cubic terms seems to have improved the level-1 residuals. Additionally, there don't appear to be any large outliers that might need to be removed. Because there are no glaring issues, we move on to the higher level residuals, again plotting the output of `hlm_resid`.
```{r}
resid2_fm1b <- hlm_resid(fm1b, level = "school", include.ls = FALSE)
resid2_fm1b

ggplot(data = resid2_fm1b, aes(x = school, y = .ranef.intercept)) + 
  geom_point() +
  labs(y = "Random effects - intercept", title = "Intercept random effects against school")
```

The random effects at the group

## pull_resid

The function `pull_resid` is an efficient way to pull a single type of residual as a vector. Whereas `hlm_resid` spends time calculating all types of residuals and fitted values, `pull_resid` only calculates the type of residual specified by the user, saving time over using `hlm_resid` and indexing for a specific column. This is especially useful when used in a loop, such as a resampler.

`pull_resid` takes three parameters, `object`, `type`, and `standardize`. The parameters `object` and `standardize` work identically as they do in `hlm_resid`, and the new parameter, `type`, can be set to:

* `"ls"` to return LS level-1 residuals
* `"eb"` to return EB level-1 residuals
* `"marginal"` to return marginal residuals

The example below illustrates the output of `pull_resid` being used to extract level-1 standardized LS residuals.
```{r}
head(pull_resid(fm1, type = "ls", standardize = TRUE))
```

The function `pull_resid` is only implemented for level-1 residuals. If the analyst wants to extract random effects for a model, they should use the `ranef` functions from either `lme4` or `nlme`.

## hlm_augment

The `hlm_augment` function combines the `hlm_resid` and `hlm_influence` functions to return a tibble containing information about the residuals and the influence diagnostics appended to the data. `hlm_augment` has three parameters, `object`, `level`, and `include.ls`, all of which have the same functionality as in `hlm_resid`. The syntax is the same for the two functions. For example, we can extract both level-1 residual and influence diagnostics from the model `fm1` with the following call.
```{r}
fm1.aug <- hlm_augment(fm1)
fm1.aug
```

This is useful for inspecting residuals values and influence diagnostics values at the same time. However, `hlm_augment` lacks some of the functionality that `hlm_influence` and `hlm_resid` have. The `delete` and `approx` parameters avaliable for `hlm_influence` are not avaliable in `hlm_augment`, so the function will always use a one step approximation and delete all observations or groups instead of a selected few. The `standardize` parameter from `hlm_resid` is also not included, so raw residuals will always be returned. If additional functionality is required, `hlm_influence` or `hlm_resid` should be used instead. `hlm_augment` is especially useful for inspecting influence diagnostics of observations with relatively high residuals, or vice versa. For more information about avaliable functionality in `hlm_influence`, see the `hlm_influence` vignette. 


