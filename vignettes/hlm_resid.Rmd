---
title: "hlm_resid"
authors: "Jack Moran, Jaylin Lowe, Adam Loy"
date: "'Sys.Date()'"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{hlm_resid}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# HLMdiag: a diagnostic tool for hierarchical (multilevel) linear models

This vignette introduces new functions concerning residual diagnostics in `HLMdiag`, specifically `hlm_resid`, `pull_resid`, and `hlm_augment`. The function `hlm_resid` is intended to replace `HLMresid` in functionality, and works more robustly with 3-level models as well as models fit with `nlme`. `hlm_resid` returns a tibble of the model frame, residuals and fitted values making it simple for an analyst to diagnose a model.

FINISH! This vignette will also explicitly state how different types of residuals are calculated and how they compare to the `resid` functions found in `lme4` and `nlme`

-introduce function 
-demo what it can do 
-explain various residuals
-cover different level options
-ls.include
-dotplot_diag can be used with the columns from hlm_influence to visually represent the different values and to illustrate 
values that go beyond the cutoff 
-mention na.action??? 

## hlm_resid function

The function `hlm_resid` takes a hierarchical linear model fit as a `lmerMod` or `lme` object and extracts residuals and predicted values from the model, using both Least Squares (LS) and Empirical Bayes (EB) methods in estimating parameters. Whereas the old function, `HLMresid`, would return a vector with a single type of residual, `hlm_resid` appends specified residuals to the data frame of the model in the form of a tibble. The use of a tibble allows the analyst to easily plot residuals against explanatory variables and identify possible outliers or model deficiencies. The function draws heavy inspiration from the `augment` function of the `broom` package, however offers more options for the types of residuals that the analyst may want to use.

## Types of residuals in multilevel models

The presence of multiple sources of variability in hierarchical linear models results in numerous quantities defining residuals. All functions in `HLMdiag` follow the classification by *Hilden-Minton (1995)* and define three types of residuals:

1. level-1 (conditional) residuals
1. higher level (random effects) residuals
1. marginal (composite) residuals

The definitions of level-1 and higher level residuals lead to different residuals depending on how the fixed and random model coefficients are estimated. `hlm_resid` implements two estimation methods: Least Squares (LS) estimation and Empirical Bayes (EB) estimation. For a comprehensive discussion of these two methods and how they are implemented, we direct the reader to the release paper for `HLMdiag` in the *Journal of Statistical Softwrare*. 

LS and EB residuals each have their own advantages and disadvantages. Level-1 LS residuals are calculated by fitting separate linear models to each group and using LS to estimate the fixed and random effects. Because they rely only on the first level of hierarchy, they are unconfounded with higher level residuals and a useful first step in diagnosing a model; however, for small group sample sizes, LS residuals are unreliable. Level-1 EB residuals are defined as the conditional modes of the random effects given the data and the estimated parameter values which are calculated with maximum likelihood. They are confounded with higher level residuals, but more robust with small sample sizes. For higher level residuals, coefficients can again be estimated using either LS or EB, but EB residuals are generally prefered due to low sample sizes. `hlm_resid` can return both LS and EB level-1 and higher level residuals as well as marginal residuals.

## Example Data

To illustrate the use of `hlm_resid`, we make use of data on exam scores of 4,059 students in 65 inner London schools. This data set is distributed as part of the R package `mlmRev` (*Bates, Maechler, and Bolker 2013b*), which makes well known multilevel modeling data sets available in R.

```{r}
data("Exam", package = "mlmRev")
head(Exam)
```

For each student, the data consist of their gender (`sex`) and two standardized exam scores—- an intake score on the London Reading Test (LRT) at age 11 (`standLRT`) and a score on the General Certificate of Secondary Education (GCSE) examination at age 16 (`normexam`). Additionally, the students’ LRT scores were used to segment students into three categories (bottom 25%, middle 50%, and top 25%) based on their verbal reasoning subscore (`vr`) and overall score (`intake)`. At the school level, the data contain the average intake score for the school (`schavg`) and type based on school gender (`schgend`, coded as mixed, boys, or girls).

## hlm_resid usage

`hlm_resid` takes 5 arguments:

* `object` - the model fit as a `lmerMod` or `lme` object.
* `level` - the level at which residuals should be extracted. The default is `level = 1`, which returns both EB and LS level-1  residuals as well as marginal residuals. Can also be set to a grouping level as defined in `object@flist` in `lme4` or in `object$groups` in `nlme`. When set to a grouping level, returns both EB and LS higher level residuals, otherwise known as the random effects for each group. 
* `standardize` - a logical indicating if the returned residuals should be standardized. The default is `standardize = FALSE`, returning raw residuasl. When `standardize = TRUE`, residuals are standardized by the sigma components of the model object. For marginal residuals, standardized residuals are equivalent to the Cholesky residuals.
* `include.ls` - a logical indicating if LS residuals should be included in the residuals returned. The default is `include.ls = TRUE`. The LS method of estimating residuals is more computationally complex than the EB method, and thus setting `include.ls = FALSE` decreases the runtime substantially on models with more observations.
* `data` - only necesarry if `na.action = na.exclude` for the model object. Data should be the data set used to fit the model containing observations with NA values.

We illustrate usage for `hlm_resid` using the exam data introduced above and fitting an initial two-level HLM using a student’s standardized London Reading Test intake score (standLRT) to explain their GCSE exam score allowing for a random intercept for each school:
```{r}
library(lme4)
fm1 <- lmer(normexam ~ standLRT + (1 | school), Exam, REML = FALSE)
fm1
```

But is this model appropriate? To assess the appropriateness of model `fm1` we must examine the level-1 and -2 residuals. To extract the standardized level-1 residuals, we call `hlm_resid` as demonstrated below.
```{r}
library(HLMdiag)
resid1_fm1 <- hlm_resid(fm1, level = 1, standardize = TRUE)
resid1_fm1
```

Utilizing the tibble output of `hlm_resid`, we can easily plot the standardized LS residuals against explanatory variables such as the standardized LRT score or against the fitted values.
```{r}
library(ggplot2)
ggplot(data = resid1_fm1, aes(x = standLRT, y = .std.ls.resid)) + 
  geom_point() +
  geom_smooth(method = "loess") + 
  labs(y = "LS level-1 residuals", title = "LS residuals against standardized LRT score")

ggplot(data = resid1_fm1, aes(x = .ls.fitted, y = .std.ls.resid)) + 
  geom_point() +
  geom_smooth(method = "loess") + 
  labs(y = "LS level-1 residuals", title = "LS residuals against LS fitted values")
```

The smoother indicates a possible 

## Multilevel data:

We illustrate the use of hlm_resid using an example of a hierarchical linear model with data from 

-CITE CLASSROOM DATA
-EXPLAIN CLASSROOM DATA
-EXPLAIN CLASSROOM MODEL
```{r setup}
class <- read.csv("http://www-personal.umich.edu/~bwest/classroom.csv")
head(class)

library(lme4)
fm.1 <- lme4::lmer(mathgain ~ mathkind + sex + minority + ses + housepov +
                     (1|schoolid/classid), data = class)
fm.1
```

The presence of multiple sources of variability in hierarchical linear models (HLMs) results in numerous quantities defining residuals. All functions in `HLMdiag` follow the classification by *Hilden-Minton (1995)* and define three types of residuals:

1. level-1 (conditional) residuals
1. level-2+ (random effects) residuals
1. marginal (composite) residuals

For the equations used to calculate the above residuals, see the release paper for `HLMdiag` in the *Journal of Statistical Software*. Note that these residuals are confounded as they are interrelated. This confounding of the residuals can lead to complications in the diagnosis of model deficiencies, since a violation in one type of residual may manifest itself as an alleged violation in a different residual. To cope with these confounded residuals *Hilden-Minton (1995)* recommends an **upward residual analysis**, as it is possible to examine level-1 residuals that are unconfounded by other residuals. This is the approach that we will follow in demonstrating the use of `hlm_resid`, starting by diagnosing level-1 residuals and then checking higher level residuals.

## hlm_resid()

The function `hlm_resid()` has 3 main parameters: `object`, `level`, and `standardize`. The `object` parameter takes the model of interest, and `standardize` takes a logical and indicates if the returned residuals should be scaled. The `level` parameter is how the analyst accesses various types of residuals, with the default, `level = 1` returning level-1 and marginal residuals and level set to a grouping factor returning higher level residuals.

Using upward analysis, we start with the level-1 residuals. To obtain standardized level-1 residuals, we use the call `hlm_resid` on our fit model, which returns a tibble.
```{r, eval = F}
library(HLMdiag)
lvl1.resid <- hlm_resid(fm.1, level = 1, standardize = TRUE)
lvl1.resid
```

-Maybe move the EB verus LS discussion here?

Note that 6 columns have been appended to the model frame.

* `.std.resid` contains the standardized Empirical Bayes (EB) residuals for each observation
* `.fitted` conatins the Empirical Bayes (EB) fitted values
* `.std.ls.resid` contains the standardized Least Squares (LS) residuals
* `.ls.fitted` contains Least Squares fitted values
* `.chol.mar.resid` contains the standaredized marginal residuals, otherwise known as the Cholesky residuals
* `.mar.fitted` contains the marginal fitted values

Typically in upwards analysis, it is preferable to look at the residuals calculated using the least squares (LS) method, as they are unconfounded with higher level residuals. However, LS residuals rely on sufficiently large sample sizes for all level-2 groups so that fixed effect and random effect coefficients can be accurately estimated for groups. Looking at the class dataset, we see that level two groups have on average 3.8 observations per group, which is troubling for the reliability of LS residuals. The warning that `hlm_resid` throws confirms this issue, and so we will examine the Empirical Bayes (EB) residuals instead, which are estimated with maximum likelihood. It should be noted that these EB residuals are confounded with higher level residuals. To return remove the LS residuals from the output, we can use the parameter, `include.ls = FALSE`.

```{r, eval = F}
lvl1.resid <- hlm_resid(fm.1, level = 1, standardize = TRUE, include.ls = FALSE)
lvl1.resid
```

Now that we have the resiudals and observations in the same tibble, it is easy to create graphics. Here we will use `ggplot2`, staying within the tidyverse.
```{r, eval = F}
library(ggplot2)
lvl1.resid$id <- as.numeric(rownames(lvl1.resid))
ggplot(data = lvl1.resid) + 
  geom_point(aes(x = id, y = .std.resid)) + 
  labs(title = "EB residuals against ID")

ggplot(data = lvl1.resid) + 
  geom_point(aes(x = mathgain, y = .std.resid)) + 
  labs(title = "EB residuals against response")

index <- which(abs(lvl1.resid$.std.resid) > 4)
lvl1.resid[index,]
```

Plotting the EB residuals against rownumber, one might miss the fact that the model overestimates high levels of mathgain and underestimates low levels of mathgain. We can a

