---
title: "hlm_influence and Influence Diagnostics in HLMdiag"
authors: "Jaylin Lowe, Jack Moran, Adam Loy"
date: "'Sys.Date()'"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{hlm_resid}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

This vignette introduces new functions concerning influence diagnostics in `HLMdiag`, specifically the `hlm_influence` and `hlm_augment` functions. It also covers new updates to the `case_delete` function, which can now be called on three level models or on `lme` models created from the `nlme` package. Additionally, this vignette compares Cook's distance values obtained through `HLMdiag` functions `case_delete` and `cooks_distance` to Cook's distance values from the `lme4`, `influence.ME`, and `car` packages and explores the differences between them. 

#hlm_influence function 

-introduce function 
-demo what it can do 
-cover different level options
-different leverage options
-different delete options
-one step approximations versus full refits 
-dotplot_diag can be used with the columns from hlm_influence to visually represent the different values and to illustrate 
values that go beyond the cutoff 
-mention na.action??? 

###Introduction 

The `hlm_influence` function provides a wrapper that returns influence diagnostics appends to the original model frame. It is useful for assessing the influence of individual observations or groups, and can also be used with `dotplot_diag` to provide an easy way of obtaining visual representations of influence diagnostics. The diagnostics returned by `hlm_influence` can include Cook's distance, MDFFITS, covariance trace (covtrace), covariance ratio (covratio), leverage, and relative variance change (RVC). 

Cook's distance and MDFFITS both measure the distance between fixed effects estimated from the full dataset and those obtained from the reduced data. For Cook's distance, the change in parameter estimates is scaled by the estimated covariance matrix of the original parameter estimates, while for MDFFITS, the change is scaled by the estimated covariance matrix of the deletion estimates. The covariance trace and covariance ratio both measure how precision is affected by the deletion of a particular observation `i`. Covariance trace is a measure of the ratio between the covariance matrices with and without unit `i` to the identity matrix, while covariance ratio is a comparison of the two covariance matrices with and without unit *i* using their determinants. Relative variance change (RVC) is a measurement of the ratio of estimates of the *l*th variance component with and without unit *i*. The final influence diagnostic returned by `hlm_influence`, leverage, is the rate of change in the predicted response with respect to the observed response. For a full explanation of these influence diagnostics, including formulas, please refer to Loy and Hofmann (2014). 


To explore the functionality of `hlm_influence`, we will use the dataset `class` from the book Linear Mixed Models: A Practical Guide Using Statistical Software (citation here). The dataset consists of 1,190 observations of students. Students are grouped within classes, which are nested within schools. There are 312 distinct classes nested within 107 schools. NEED MORE INFORMATION ABOUT DATASET HERE.  

```{r}
class <- read.csv("http://www-personal.umich.edu/~bwest/classroom.csv")
class <- as_tibble(class)
class
```

We will fit a simple three level hierarchical linear model using the `lme4` package: 
```{r}
class.lmer <- lme4::lmer(mathgain ~ mathkind + sex + minority + ses + housepov + (1|schoolid/classid), data = class)
```

###Obtain influence diagnostics at different levels with `level`
`hlm_influence` can be used to obtain influence diagnostics for each individual case, or larger groups. For example, to obtain a tibble with influence diagnostics for all 1,190 students we can use the following:
```{r}
infl <- hlm_influence(class.lmer, level = 1)
infl
```
Note that the parameter used to select individual observations is now called `level`, not `group`. Previous versions of `HLMdiag` used the group parameter for influence diagnostics, where `group = NULL` was the default, and users could choose to delete groups instead by setting `group` equal to level names. As of `HLMdiag` version 0.4.0, `group` has been replaced by `level`. `level` defaults to `level = 1` which deletes individual observations, exactly how `group = NULL` used to work. 

The resulting tibble can be used along with `dotplot_diag` to identify potentially influential observations using either an internal caculated cutoff of 3*IQR or a provided cutoff. For example, the plot shown below reveals and labels all observations above the internally calculated cutoff for Cook's distance.  
```{r}
dotplot_diag(infl$cooksd, name = "cooks.distance", cutoff = "internal")
```

The plot illustrates that there are many observations with a Cook's distance value above the internally calculated cutoff. `dotplot_diag` labels the top 5, which is difficult to see in this case. Rather than investigate all observations above the cutoff, we may be interested in the observations with the highest Cook's distance values. The tibble returned by `hlm_influence` provides an easy way to do this when used with the `arrange` function from `dplyr`. 
```{r}
infl %>%
  arrange(desc(cooksd))
```
We can see that there does not appear to be a clear pattern among students who have relatively higher Cook's distance values; they do not tend to be from a particular school or class. In order to investigate these observations further, one could look to summary statistics for the different explanatory variables. Additionally, a similar analysis could be done with the other influence diagnostics provided in the tibble from `hlm_influence`. 

In addition to identifying influencial observations, it may also be useful to identify influential groups. The `level` parameter in `hlm_influence` can be used for this purpose. For example, we can obtain influence diagnostics for each class:
```{r}
infl.classes <- hlm_influence(class.lmer, level = "classid:schoolid")
infl.classes
```
Note that the `level` parameter is set as `classid:schoolid`, not `classid`. The level parameter should be specified as found in `model@flist` for lmerMod objects. For three level models, this usually takes the form of "level2:level3", where level2 is the name of the second level variable, and level3 is the name of the third level variable. 

Using `dotplot_diag` again with one of the columns from the resulting tibble of `hlm_influence` reveals that class 218 has a relatively high Cook's distance value. 
```{r}
dotplot_diag(infl.classes$cooksd, name = "cooks.distance", cutoff = "internal")
```

We can repeat a similar analysis to flag influencial schools. 
```{r}
infl.schools <- hlm_influence(class.lmer, level = "schoolid")
infl.schools
```

Similarily, we can use `dotplot_diag` to visually represent the differences. In this case, there are only four observations above the cutoff, so we set `modify = "dotplot"` in order to better visualize the influential observations. `modify = boxplot` works well when there are a relatively small number of observations above the cutoff. 
```{r}
dotplot_diag(infl.schools$cooksd, name = "cooks.distance", cutoff = "internal", modify = "dotplot")
```

The plot reveals that schools 68, 75, 70, and 27 have relatively high Cook's distance values. 

###Investigate deletion of specific observations or groups with `delete`

The `delete` parameter allows for investigation of influence diagnostics for a specified group of observations or groups. 
For example, influence diagnostics for the influential schools flagged above (68, 75, 70, and 27) can be calculated as shown below: 
```{r}
hlm_influence(class.lmer, level = "schoolid", delete = c("27", "70", "75", "68"))
```
Note that in this case, `delete` is specified as a character vector consisting of the school ID's of interest. `delete` can also be set as a numeric vector of indices; in this case, setting `delete` to the row numbers of all students in the data frame who attend schools 68, 75, 70, or 27 would be equivalent to the line above. 

###Select different types of leverage with `leverage` argument

In the previous examples, `hlm_influence` only returned overall leverage. However, `hlm_influence` also allows for other types of leverage, including the leverage corresponding to the fixed effects, the leverage corresponding to the random effects as proposed by Demidenko and Stukel (2005), and the unconfounded leverage corresponding to the random effects proposed by Nobre and Singer (2011). These types of leverage are referred to as `fixef`, `ranef`, and `ranef.uc`, respectively. 

We can see that none of our observations are flagged for high leverage when looking only at overall leverage:
```{r}
dotplot_diag(infl2$leverage.overall, name = "leverage", cutoff = "internal")
```


However, we can obtain the other types of leverage as follows: 
```{r}
infl2 <- hlm_influence(class.lmer, level = 1, leverage = c("overall", "fixef", "ranef", "ranef.uc"))
```
This example illustrates how to select all four types of leverage, but any one or more may also be selected. 


```{r}
dotplot_diag(infl2$leverage.fixef, name = "leverage", cutoff = "internal", modify = "dotplot")
```
However, futher analysis reveals that several observations have high leverage when considering only the leverage corresponding to the fixed effects. 

###Choose between approximations or full refits with `approx`

`hlm_influence` defaults to calculating influence diagnostics based off a one step approximation (Christensen et.al 1992; Shi andChen 2008; Zewotir 2008). However, the `approx` parameter allows the user to calculate influence diagnostics based off a full refit of the data using `hlm_influence`. For example, if we wished to calculate influence diagnostics for each school by fully refitting the model each time, we could use:
```{r}
hlm_influence(class.lmer, level = "schoolid", approx = FALSE)
```

In most cases, using the default of `approx = TRUE` is sufficient for influence analysis. Setting `approx = FALSE` also takes much longer than the default setting since the model must be refit each time with each group or observation deleted. However, the full refit method also allows for relative variance change (RVC) to be returned. If this is desired, `approx = FALSE` should be used. 

#na.action and the `data` argument 
`hlm_influence` was written to respect the `na.action` parameter from the `lme4` package. This argument defaults to `na.omit`, which means all rows in the datasets with `NA`s present are simply deleted from the model. However, there is also an `na.exclude` option, which pads the resulting tibbles with `NA`s in the the rows that contained `NA`s in the original dataset in place of deleting them altogether. In order to do this, the original dataset must be passed into `hlm_influence` via the `data` argument whenever the `na.action` was set to `"na.exclude"` in the model fitting process. 

For example, while the `class` dataset does not have any `NA`s in the dataset, we can introduce a couple for the purposes of an example.
```{r}
classNA <- class
classNA[2,3] <- NA
classNA[3,4] <- NA
```

We can then fit the same model using the `lme4` package as before. 
```{r}
class.lmer.exclude <- lme4::lmer(mathgain ~ mathkind + sex + minority + ses + housepov + (1|schoolid/classid), data = classNA, na.action = "na.exclude")
class.lmer.omit <- lme4::lmer(mathgain ~ mathkind + sex + minority + ses + housepov + (1|schoolid/classid), data = classNA)
```

We then run `hlm_influence` on the model where `na.action = "na.omit"`, the default.
```{r}
hlm_influence(class.lmer.omit, level = 1)
```
Note than there are only 1,188 rows in the returned tibble, although there were 1,190 observations in the original dataset. The two rows with NAs were deleted from the returned tibble. 

We can repeat this with the model where `na.action = "na.exclude"`. 
```{r}
hlm_influence(class.lmer.exclude, level = 1, data = classNA)
```
In this tibble, there are 1,190 rows. Furthermore, the two rows with NAs display NAs for the influence diagnostics, instead of being entirely absent in the above example. Additionally, notice that with this model, the `data` argument was necessary. Failing to provide the dataset through the `data` argument in this situation will result in an error. 

#hlm_augment function 

The `hlm_augment` function combines the `hlm_resid` and `hlm_influence` functions to return a tibble containing information about the residuals and the influence diagnostics appended to the data. For example, we can obtain residuals and influence diagnostics at once for all students in the `class` dataset with the following:
```{r}
aug <- hlm_augment(class.lmer, level = 1)
aug
```
This is useful for inspecting residuals values and influence diagnostics values at the same time. However, `hlm_augment` lacks some of the functionality that `hlm_influence` and `hlm_resid` have. The `delete` and `approx` parameters avaliable for `hlm_influence` are not avaliable in `hlm_augment`, so the function will always use a one step approximation and delete all observations or groups instead of a selected few. The `sim` and `include.ls` parameters from `hlm_resid` are also not included, so `hlm_influence` or `hlm_resid` should be used instead if this functionality is desired. 

`hlm_augment` is especially useful for inspecting residual values of observations with relatively high influence diagnostics values, or vice versa. 
```{r}
aug %>%
  arrange(desc(cooksd))
```
Similar to `hlm_influence` we can sort by a particular column in order to inspect the values of other influence diagnostics and the residuals of influential observations. 

#lme objects from nlme package 
Previously, only the individual one step approximation influence functions worked on `lme` models fit using the `nlme` package. However, `hlm_influence` can also be used on `lme` objects, as can `hlm_augment`. The `case_delete` function in `HLMdiag` has also been updated so it can be used with `lme` objects, rather than only `lmerMod` objects, as was previously the case. For more information on using `case_delete`, see the following section. 

###Important differences for lme objects 
In most cases, using a `lme` object for `hlm_influence` or `hlm_augment` is identical to their usage with `lmerMod` objects from `lme4`. However, there are a few notable exceptions. 

For both `hlm_influence` and `hlm_augment`, levels should be specified by names that appear in `model@flist`. For the second level of a three level `lmerMod` model, this usually looks like "level2:level3" where level2 and level3 are the names of the second and third level variables, respectively. However, for a `lme` model, levels should be specified by names that appear in `model$groups`. For example, we can obtain influence diagnostics for each classroom from the `class` dataset in the following way:
```{r}
class.lme <- nlme::lme(mathgain ~ mathkind + sex + minority + ses + housepov, random = ~ 1|schoolid/classid, data = class)
#hlm_influence(class.lme, level = "classid") #this is breaking right now- hopefully it's just something Adam's doing 
```




-no data argument for na's 
-difference in how things are named in flist 

#case_delete with 3 level models 

#Cook's distance values comparison to other packages 
